{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Детекирование объектов на фотографиях с использованием YOLOv8\n",
    "\n",
    "<center><img src='./img/CV_10_4_1.png'></img></center>\n",
    "\n",
    "В [<b>другом ноутбуке</b>](./fcrnn.ipynb) используется модель *Faster R-CNN*\n",
    "\n",
    "## <center>Подготовка датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available accelerator: cuda\n",
      "\n",
      "Fri Jan 26 21:07:24 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.40.06              Driver Version: 551.23         CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3080 Ti     On  |   00000000:01:00.0  On |                  N/A |\n",
      "|  0%   44C    P8             25W /  370W |    3277MiB /  12288MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A        23      G   /Xwayland                                   N/A      |\n",
      "|    0   N/A  N/A    135554      C   /python3.11                                 N/A      |\n",
      "|    0   N/A  N/A    209514      C   /python3.11                                 N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "from ultralytics.utils.ops import xyxy2xywh\n",
    "import torch\n",
    "import pickle\n",
    "import shutil\n",
    "import os\n",
    "import time\n",
    "import re\n",
    "from data_classes.custom_dataset import CustomImageDataset\n",
    "DATA_PATH = './data/VOC2012/'\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Available accelerator: {DEVICE}\\n')\n",
    "if DEVICE == 'cuda':\n",
    "    !nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запишем в переменные путь к датасету"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_annotations = './data/VOC2012/Annotations/'\n",
    "data_path_images = './data/VOC2012/JPEGImages/'\n",
    "yolo_data_path = './datasets/yolo_data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим уже обученный энкодер для классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./model/label_encoder.pkl', 'rb') as encoder_file:\n",
    "    label_encoder = pickle.load(encoder_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим датафреймы для каждой выборки *train*, *valid*, *test*. Конвертируем координаты из формата $\\{x_{min}, y_{min}, x_{max}, y_{max}\\}$ в формат $\\{x_{c}, y_{c}, w, h\\}$\n",
    "\n",
    "Для формирования и разделения выборок (в данном случае удобнее использовать именно датафреймы) используется [<b>собственный класс датасета</b>](./data_classes/custom_dataset.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>label</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "      <th>xcenter</th>\n",
       "      <th>ycenter</th>\n",
       "      <th>box_width</th>\n",
       "      <th>box_height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008_007231.jpg</td>\n",
       "      <td>18</td>\n",
       "      <td>375</td>\n",
       "      <td>500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>365.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.488000</td>\n",
       "      <td>0.759000</td>\n",
       "      <td>0.970667</td>\n",
       "      <td>0.482000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010_002860.jpg</td>\n",
       "      <td>17</td>\n",
       "      <td>500</td>\n",
       "      <td>375</td>\n",
       "      <td>1.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>373.0</td>\n",
       "      <td>0.501000</td>\n",
       "      <td>0.685333</td>\n",
       "      <td>0.998000</td>\n",
       "      <td>0.618667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008_003108.jpg</td>\n",
       "      <td>14</td>\n",
       "      <td>191</td>\n",
       "      <td>500</td>\n",
       "      <td>69.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.680628</td>\n",
       "      <td>0.556000</td>\n",
       "      <td>0.638743</td>\n",
       "      <td>0.888000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2007_006673.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "      <td>333</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>324.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>0.618000</td>\n",
       "      <td>0.459459</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.258258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012_001778.jpg</td>\n",
       "      <td>14</td>\n",
       "      <td>375</td>\n",
       "      <td>500</td>\n",
       "      <td>219.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>323.0</td>\n",
       "      <td>440.0</td>\n",
       "      <td>0.722667</td>\n",
       "      <td>0.665000</td>\n",
       "      <td>0.277333</td>\n",
       "      <td>0.430000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              name  label  width  height   xmin   ymin   xmax   ymax  \\\n",
       "0  2008_007231.jpg     18    375     500    1.0  259.0  365.0  500.0   \n",
       "1  2010_002860.jpg     17    500     375    1.0  141.0  500.0  373.0   \n",
       "2  2008_003108.jpg     14    191     500   69.0   56.0  191.0  500.0   \n",
       "3  2007_006673.jpg      3    500     333  294.0  110.0  324.0  196.0   \n",
       "4  2012_001778.jpg     14    375     500  219.0  225.0  323.0  440.0   \n",
       "\n",
       "    xcenter   ycenter  box_width  box_height  \n",
       "0  0.488000  0.759000   0.970667    0.482000  \n",
       "1  0.501000  0.685333   0.998000    0.618667  \n",
       "2  0.680628  0.556000   0.638743    0.888000  \n",
       "3  0.618000  0.459459   0.060000    0.258258  \n",
       "4  0.722667  0.665000   0.277333    0.430000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = CustomImageDataset(DATA_PATH, label_encoder, split='train').df.copy()\n",
    "valid_df = CustomImageDataset(DATA_PATH, label_encoder, split='valid').df.copy()\n",
    "test_df = CustomImageDataset(DATA_PATH, label_encoder, split='test').df.copy()\n",
    "\n",
    "for df in [train_df, valid_df, test_df]:\n",
    "    df[['xcenter', 'ycenter', 'box_width', 'box_height']] = xyxy2xywh(df[['xmin', 'ymin', 'xmax', 'ymax']].values)\n",
    "    df['xcenter'] = df['xcenter'] / df['width']\n",
    "    df['ycenter'] = df['ycenter'] / df['height']\n",
    "    df['box_width'] = df['box_width'] / df['width']\n",
    "    df['box_height'] = df['box_height'] / df['height']\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделаем правильный формат датасета для модели *YOLO*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample, df in [('train', train_df), ('val', valid_df), ('test', test_df)]:\n",
    "    sample_path_imgs = os.path.join(yolo_data_path, 'images', sample)\n",
    "    sample_path_labels = os.path.join(yolo_data_path, 'labels', sample)\n",
    "    if not os.path.exists(sample_path_imgs):\n",
    "        os.makedirs(sample_path_imgs)\n",
    "    if not os.path.exists(sample_path_labels):\n",
    "        os.makedirs(sample_path_labels)\n",
    "    unique_images = df['name'].unique()\n",
    "    for img in unique_images:\n",
    "        img_df = df[df['name'] == img]\n",
    "        labels_string = ''\n",
    "        for row in img_df.iterrows():\n",
    "            row_series = row[1]\n",
    "            row_label = f'{row_series.label} {row_series.xcenter} {row_series.ycenter} {row_series.box_width} {row_series.box_height}\\n'\n",
    "            labels_string += row_label\n",
    "        shutil.copy(os.path.join(data_path_images, img), os.path.join(yolo_data_path, 'images', sample))\n",
    "        txt_name = re.sub(r'\\.+[a-z]*', '.txt', img)\n",
    "        with open(os.path.join(yolo_data_path, 'labels', sample, txt_name), 'w') as txt_label:\n",
    "            txt_label.write(labels_string.rstrip('\\n'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим, что датасет сформирован верно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m./datasets\u001b[0m\n",
      "└── \u001b[01;34myolo_data\u001b[0m\n",
      "    ├── \u001b[01;34mimages\u001b[0m\n",
      "    │   ├── \u001b[01;34mtest\u001b[0m\n",
      "    │   ├── \u001b[01;34mtrain\u001b[0m\n",
      "    │   └── \u001b[01;34mval\u001b[0m\n",
      "    └── \u001b[01;34mlabels\u001b[0m\n",
      "        ├── \u001b[01;34mtest\u001b[0m\n",
      "        ├── \u001b[01;34mtrain\u001b[0m\n",
      "        └── \u001b[01;34mval\u001b[0m\n",
      "\n",
      "9 directories\n"
     ]
    }
   ],
   "source": [
    "!tree ./datasets -d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Обучение модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим (*fine-tuning*) модель средней сложности (с суффиксом `m`) на 40 эпохах, которая подойдет даже для **обработки видео**, если имеется достаточная вычислительная мощность\n",
    "\n",
    "[<b>voc.yaml</b>](./voc.yaml) - файл, необходимый для изменения конфигурации модели: путь к выборкам, количество классов и их расшифровка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.1.6 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.1.5 🚀 Python-3.11.5 torch-2.1.2+cu121 CUDA:0 (NVIDIA GeForce RTX 3080 Ti, 12288MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8m.pt, data=voc.yaml, epochs=40, time=None, patience=50, batch=8, imgsz=512, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=True, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-26 16:32:08.180017: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-26 16:32:08.180052: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-26 16:32:08.214133: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding model.yaml nc=80 with nc=20\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   3787276  ultralytics.nn.modules.head.Detect           [20, [192, 384, 576]]         \n",
      "Model summary: 295 layers, 25867900 parameters, 25867884 gradients, 79.1 GFLOPs\n",
      "\n",
      "Transferred 469/475 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/deep_learning/Object detection/datasets/yolo_data/labels/train.cache... 14070 images, 0 backgrounds, 0 corrupt: 100%|██████████| 14070/14070 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/deep_learning/Object detection/datasets/yolo_data/labels/val.cache... 4772 images, 0 backgrounds, 0 corrupt: 100%|██████████| 4772/4772 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/detect/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000417, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 512 train, 512 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
      "Starting training for 40 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/40      2.79G     0.9232      1.664      1.226         23        512: 100%|██████████| 1759/1759 [02:49<00:00, 10.37it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 299/299 [00:24<00:00, 12.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4772       6021      0.276      0.488      0.276      0.188\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/40      2.87G       1.09      1.735      1.367         20        512: 100%|██████████| 1759/1759 [02:32<00:00, 11.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 299/299 [00:23<00:00, 12.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4772       6021      0.273      0.393      0.239       0.16\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/40      2.88G      1.135      1.804      1.401         35        512: 100%|██████████| 1759/1759 [02:27<00:00, 11.95it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 299/299 [00:22<00:00, 13.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4772       6021      0.272      0.409      0.238      0.159\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/40      2.89G      1.124      1.774      1.398         28        512: 100%|██████████| 1759/1759 [02:28<00:00, 11.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 299/299 [00:21<00:00, 13.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4772       6021      0.301      0.397      0.254       0.17\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/40      2.89G      1.096      1.713      1.379         28        512: 100%|██████████| 1759/1759 [02:27<00:00, 11.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 299/299 [00:21<00:00, 13.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4772       6021       0.29       0.42      0.268      0.187\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/40      2.89G      1.056      1.616      1.355         21        512: 100%|██████████| 1759/1759 [02:33<00:00, 11.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 299/299 [00:22<00:00, 13.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4772       6021      0.321      0.463      0.299      0.215\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/40      2.88G      1.028      1.559      1.334         30        512: 100%|██████████| 1759/1759 [02:35<00:00, 11.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 299/299 [00:23<00:00, 12.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4772       6021      0.306       0.48      0.311      0.226\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/40      2.89G      1.002      1.506      1.317         27        512: 100%|██████████| 1759/1759 [02:30<00:00, 11.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 299/299 [00:22<00:00, 13.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4772       6021      0.328      0.472      0.323      0.236\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/40      2.88G     0.9801      1.454      1.299         41        512: 100%|██████████| 1759/1759 [02:30<00:00, 11.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 299/299 [00:20<00:00, 14.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4772       6021      0.326      0.504      0.322      0.239\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/40      2.88G     0.9661      1.422      1.291         26        512: 100%|██████████| 1759/1759 [02:24<00:00, 12.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 299/299 [00:20<00:00, 14.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4772       6021      0.319       0.51      0.321      0.237\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/40      2.95G     0.9465      1.389      1.272         19        512: 100%|██████████| 1759/1759 [02:29<00:00, 11.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 299/299 [00:23<00:00, 12.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4772       6021      0.328      0.516      0.338      0.254\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/40      2.87G      0.934      1.353      1.264         41        512: 100%|██████████| 1759/1759 [02:34<00:00, 11.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 299/299 [00:20<00:00, 14.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4772       6021      0.325      0.513      0.335      0.254\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/40      2.93G     0.9209      1.324      1.255         23        512: 100%|██████████| 1759/1759 [02:33<00:00, 11.44it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 299/299 [00:21<00:00, 13.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4772       6021      0.331       0.52       0.34      0.255\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/40      2.93G     0.9026      1.292      1.246         32        512: 100%|██████████| 1759/1759 [02:33<00:00, 11.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 299/299 [00:21<00:00, 13.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4772       6021       0.34      0.543      0.347      0.267\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/40      2.87G     0.8838      1.262      1.232         18        512: 100%|██████████| 1759/1759 [02:32<00:00, 11.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 299/299 [00:21<00:00, 14.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4772       6021       0.35      0.515      0.347      0.269\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/40      2.87G     0.8809       1.24      1.228         22        512: 100%|██████████| 1759/1759 [02:34<00:00, 11.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 299/299 [00:22<00:00, 13.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4772       6021       0.32      0.574       0.35      0.268\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/40      2.88G     0.8696       1.22      1.221         22        512: 100%|██████████| 1759/1759 [02:33<00:00, 11.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 299/299 [00:21<00:00, 13.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4772       6021      0.322      0.572      0.344      0.262\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/40      2.89G     0.8516      1.186      1.207         27        512: 100%|██████████| 1759/1759 [02:34<00:00, 11.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 299/299 [00:21<00:00, 14.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4772       6021      0.331      0.557      0.355      0.274\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/40      2.84G     0.8444      1.169      1.201         13        512: 100%|██████████| 1759/1759 [02:32<00:00, 11.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 299/299 [00:20<00:00, 14.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4772       6021      0.319      0.583      0.357      0.278\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/40      2.96G     0.8378      1.147      1.201         20        512: 100%|██████████| 1759/1759 [02:30<00:00, 11.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 299/299 [00:21<00:00, 13.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4772       6021       0.32       0.59      0.347       0.27\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/40      2.96G     0.8274      1.123      1.188         32        512: 100%|██████████| 1759/1759 [02:35<00:00, 11.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 299/299 [00:21<00:00, 13.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4772       6021      0.314      0.595      0.352      0.275\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/40      2.88G     0.8196      1.105      1.182         15        512: 100%|██████████| 1759/1759 [02:34<00:00, 11.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 299/299 [00:21<00:00, 13.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4772       6021      0.326      0.582      0.356      0.279\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      23/40      2.94G     0.8049      1.081      1.172         21        512: 100%|██████████| 1759/1759 [02:32<00:00, 11.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 299/299 [00:22<00:00, 13.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4772       6021      0.311      0.632      0.349      0.272\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      24/40      2.87G     0.7988      1.064      1.167         22        512: 100%|██████████| 1759/1759 [02:29<00:00, 11.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 299/299 [00:20<00:00, 14.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4772       6021      0.317      0.588      0.351      0.276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      25/40      2.88G     0.7815      1.034      1.153         20        512: 100%|██████████| 1759/1759 [02:28<00:00, 11.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 299/299 [00:21<00:00, 13.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4772       6021      0.317      0.599      0.355      0.281\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      26/40      2.87G       0.78      1.027      1.154         22        512: 100%|██████████| 1759/1759 [02:30<00:00, 11.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 299/299 [00:21<00:00, 13.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4772       6021      0.311      0.601      0.338      0.267\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      27/40      2.88G     0.7692      1.005      1.146         19        512: 100%|██████████| 1759/1759 [02:30<00:00, 11.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 299/299 [00:21<00:00, 14.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4772       6021       0.31      0.609      0.332      0.262\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      28/40      2.88G     0.7604     0.9918      1.141         21        512: 100%|██████████| 1759/1759 [02:28<00:00, 11.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 299/299 [00:21<00:00, 13.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4772       6021      0.305      0.622      0.342       0.27\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      29/40      2.84G     0.7526     0.9763      1.136         22        512: 100%|██████████| 1759/1759 [02:34<00:00, 11.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 299/299 [00:22<00:00, 13.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4772       6021      0.297      0.636      0.342       0.27\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      30/40      2.96G     0.7427     0.9535      1.129         38        512: 100%|██████████| 1759/1759 [02:35<00:00, 11.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 299/299 [00:22<00:00, 13.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4772       6021      0.295      0.639      0.341      0.272\n",
      "Closing dataloader mosaic\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      31/40      2.86G     0.6658     0.7748       1.05          9        512: 100%|██████████| 1759/1759 [02:35<00:00, 11.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 299/299 [00:22<00:00, 13.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4772       6021       0.29      0.638      0.326      0.258\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      32/40      2.88G     0.6526     0.7479      1.043         14        512: 100%|██████████| 1759/1759 [02:34<00:00, 11.36it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 299/299 [00:22<00:00, 13.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4772       6021      0.292      0.621      0.326       0.26\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      33/40      2.87G     0.6383     0.7238      1.032         14        512: 100%|██████████| 1759/1759 [02:35<00:00, 11.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 299/299 [00:22<00:00, 13.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4772       6021      0.277      0.637      0.317      0.252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      34/40      2.87G     0.6304     0.7054      1.026         23        512: 100%|██████████| 1759/1759 [02:34<00:00, 11.36it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 299/299 [00:22<00:00, 13.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4772       6021      0.278      0.641      0.313      0.249\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      35/40      2.88G     0.6196     0.6797      1.015          9        512: 100%|██████████| 1759/1759 [02:33<00:00, 11.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 299/299 [00:21<00:00, 14.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4772       6021      0.275      0.644      0.308      0.246\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      36/40      2.88G     0.6069     0.6569      1.007          9        512: 100%|██████████| 1759/1759 [02:34<00:00, 11.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 299/299 [00:22<00:00, 13.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4772       6021      0.271      0.655      0.301       0.24\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      37/40      2.88G     0.5988     0.6352      1.002         13        512: 100%|██████████| 1759/1759 [02:30<00:00, 11.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 299/299 [00:23<00:00, 12.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4772       6021      0.268      0.639      0.294      0.235\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      38/40      2.87G     0.5897     0.6224     0.9966         21        512: 100%|██████████| 1759/1759 [02:32<00:00, 11.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 299/299 [00:21<00:00, 13.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4772       6021      0.263      0.651      0.289      0.229\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      39/40      2.86G     0.5784     0.6044     0.9883         11        512: 100%|██████████| 1759/1759 [02:32<00:00, 11.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 299/299 [00:21<00:00, 13.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4772       6021      0.264      0.621      0.285      0.225\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      40/40      2.87G     0.5743     0.5851     0.9846          9        512: 100%|██████████| 1759/1759 [02:33<00:00, 11.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 299/299 [00:21<00:00, 13.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4772       6021      0.258      0.634      0.278      0.219\n",
      "\n",
      "40 epochs completed in 1.950 hours.\n",
      "Optimizer stripped from runs/detect/train/weights/last.pt, 52.0MB\n",
      "Optimizer stripped from runs/detect/train/weights/best.pt, 52.0MB\n",
      "\n",
      "Validating runs/detect/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.1.5 🚀 Python-3.11.5 torch-2.1.2+cu121 CUDA:0 (NVIDIA GeForce RTX 3080 Ti, 12288MiB)\n",
      "Model summary (fused): 218 layers, 25851340 parameters, 0 gradients, 78.7 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 299/299 [00:22<00:00, 13.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4772       6021      0.318      0.597      0.355      0.281\n",
      "             aeroplane       4772        155      0.466      0.754      0.535      0.457\n",
      "               bicycle       4772        127      0.339      0.496      0.424      0.342\n",
      "                  bird       4772        192      0.363      0.693      0.514      0.384\n",
      "                  boat       4772        157      0.246      0.401      0.233      0.155\n",
      "                bottle       4772        236      0.203      0.521      0.156       0.11\n",
      "                   bus       4772         96      0.319      0.771      0.305      0.263\n",
      "                   car       4772        370       0.25      0.508      0.279      0.215\n",
      "                   cat       4772        192      0.622      0.806      0.695       0.58\n",
      "                 chair       4772        501       0.19      0.395      0.155      0.102\n",
      "                   cow       4772        122       0.29      0.672      0.339      0.261\n",
      "           diningtable       4772        109       0.18      0.486      0.147      0.106\n",
      "                   dog       4772        237       0.47      0.734      0.569      0.484\n",
      "                 horse       4772        123      0.348      0.602      0.452      0.365\n",
      "             motorbike       4772        112      0.309      0.696      0.414      0.333\n",
      "                person       4772       2598      0.334      0.684       0.41      0.319\n",
      "           pottedplant       4772        190      0.169      0.326       0.13     0.0765\n",
      "                 sheep       4772        148      0.247      0.662      0.243      0.182\n",
      "                  sofa       4772        115       0.21      0.548      0.215       0.17\n",
      "                 train       4772        103      0.546      0.748      0.648      0.541\n",
      "             tvmonitor       4772        138      0.264      0.428       0.24      0.182\n",
      "Speed: 0.1ms preprocess, 1.7ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/train\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "yolo = YOLO('yolov8m.pt')\n",
    "results = yolo.train(model='yolov8m.pt', data='voc.yaml', epochs=40, imgsz=512, batch=8, pretrained=True, visualize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отобразим, как менялись целевые метрики и функции потерь в зависимости от эпохи\n",
    "\n",
    "![](./runs/detect/train/results.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что **переобучение** началось примерно с 20й эпохи\n",
    "\n",
    "Загрузим лучшую модель (не последнюю) на основе показателей метрик/функции потерь **валидационной выборки**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_path = './runs/detect/train/weights/best.pt'\n",
    "best_yolo = YOLO(best_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Оценка качества"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделаем валидацию на **тестовой выборке** и отобразим графики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.5 🚀 Python-3.11.5 torch-2.1.2+cu121 CUDA:0 (NVIDIA GeForce RTX 3080 Ti, 12288MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/deep_learning/Object detection/datasets/yolo_data/labels/test... 4833 images, 0 backgrounds, 0 corrupt: 100%|██████████| 4833/4833 [00:02<00:00, 2026.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/deep_learning/Object detection/datasets/yolo_data/labels/test.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 303/303 [00:28<00:00, 10.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4833       6021      0.302      0.606      0.339      0.263\n",
      "             aeroplane       4833        146      0.493      0.781      0.573      0.442\n",
      "               bicycle       4833        124      0.261      0.468      0.341      0.276\n",
      "                  bird       4833        189      0.368      0.704      0.495      0.368\n",
      "                  boat       4833        161      0.242      0.477      0.209      0.149\n",
      "                bottle       4833        232      0.171      0.444      0.148      0.103\n",
      "                   bus       4833        110      0.288        0.7       0.28       0.23\n",
      "                   car       4833        378      0.263      0.545      0.274      0.206\n",
      "                   cat       4833        191        0.6      0.796      0.708      0.591\n",
      "                 chair       4833        416      0.164      0.411      0.131     0.0858\n",
      "                   cow       4833        109      0.268      0.651      0.291      0.231\n",
      "           diningtable       4833        131      0.183      0.429       0.16      0.109\n",
      "                   dog       4833        242      0.445      0.756      0.523      0.435\n",
      "                 horse       4833        118      0.307      0.653       0.46      0.374\n",
      "             motorbike       4833        128      0.289      0.628       0.37      0.278\n",
      "                person       4833       2623      0.326      0.705      0.415       0.32\n",
      "           pottedplant       4833        171      0.146       0.38      0.133     0.0839\n",
      "                 sheep       4833        177      0.266      0.678      0.258      0.189\n",
      "                  sofa       4833        137      0.241       0.62      0.251      0.202\n",
      "                 train       4833        108      0.472      0.802      0.481      0.388\n",
      "             tvmonitor       4833        130      0.242        0.5       0.27      0.204\n",
      "Speed: 0.1ms preprocess, 3.1ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "test_metrics = best_yolo.val(split='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./runs/detect/val/confusion_matrix_normalized.png)\n",
    "\n",
    "По матрице ошибок видно, что модель почти не путается между классами (низкое количество *FP* и *FN*)\n",
    "\n",
    "![](./runs/detect/val/F1_curve.png)\n",
    "\n",
    "Наибольшее значение $F_1$-score находится около уровня уверенности $\\approx 0.35$\n",
    "\n",
    "![](./runs/detect/val/PR_curve.png)\n",
    "\n",
    "$\\text{mAP@50} \\approx 0.339$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравнение c *Faster R-CNN* находится в [<b>readme файле</b>](./README.md)\n",
    "\n",
    "Отобразим несколько тестовых примеров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 512x512 1 person, 1: 512x512 3 persons, 2: 512x512 1 aeroplane, 2 persons, 3: 512x512 1 train, 4: 512x512 1 cow, 5: 512x512 1 boat, 6: 512x512 5 persons, 7: 512x512 3 aeroplanes, 8: 512x512 1 person, 9: 512x512 2 cars, 1 dog, 266.9ms\n",
      "Speed: 1.4ms preprocess, 26.7ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 512)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "test_path = os.path.join(yolo_data_path, 'images', 'test')\n",
    "test_images = [os.path.join(test_path, test_img) for test_img in os.listdir(test_path)]\n",
    "test_preds = best_yolo.predict(test_images[:10], save=True, conf=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./runs/detect/predict/2007_008571.jpg)\n",
    "![](./runs/detect/predict/2008_000026.jpg)\n",
    "![](./runs/detect/predict/2008_002451.jpg)\n",
    "![](./runs/detect/predict/2008_002958.jpg)\n",
    "![](./runs/detect/predict/2008_006055.jpg)\n",
    "![](./runs/detect/predict/2009_000397.jpg)\n",
    "![](./runs/detect/predict/2010_004598.jpg)\n",
    "![](./runs/detect/predict/2010_000444.jpg)\n",
    "![](./runs/detect/predict/2011_001257.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Замерим, сколько времени необходимо сети для обработки одного изображения, чтобы сравнить результаты с *Faster R-CNN*. Результаты сравнения будут в [<b>readme файле</b>](./README.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/deep_learning/Object detection/data/VOC2012/JPEGImages/2007_000027.jpg: 512x512 1 person, 52.9ms\n",
      "Speed: 2.2ms preprocess, 52.9ms inference, 1.6ms postprocess per image at shape (1, 3, 512, 512)\n",
      "0.06300 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "one_pred_time = best_yolo.predict('./data/VOC2012/JPEGImages/2007_000027.jpg')\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "print(f'{total_time:.5f} seconds')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
